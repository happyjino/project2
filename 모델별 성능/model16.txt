1/1 [==============================] - 0s 145ms/step
./my_writing_dataset/test/01.JPG
0: 0.992
1: 0.000
2: 0.000
3: 0.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 0.000
9: 0.007
1/1 [==============================] - 0s 88ms/step
./my_writing_dataset/test/02.JPG
0: 0.092
1: 0.000
2: 0.000
3: 0.001
4: 0.000
5: 0.000
6: 0.253
7: 0.000
8: 0.003
9: 0.651
1/1 [==============================] - 0s 94ms/step
./my_writing_dataset/test/03.JPG
0: 0.002
1: 0.000
2: 0.002
3: 0.003
4: 0.000
5: 0.000
6: 0.001
7: 0.001
8: 0.000
9: 0.990
1/1 [==============================] - 0s 91ms/step
./my_writing_dataset/test/11.JPG
0: 0.000
1: 0.956
2: 0.001
3: 0.001
4: 0.012
5: 0.002
6: 0.001
7: 0.008
8: 0.002
9: 0.017
WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EDC1595280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has 
reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing 
and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
1/1 [==============================] - 0s 87ms/step
./my_writing_dataset/test/2.jpg
0: 0.000
1: 0.000
2: 0.000
3: 1.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 0.000
9: 0.000
WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EDC1595C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has 
reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing 
and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
1/1 [==============================] - 0s 92ms/step
./my_writing_dataset/test/21.JPG
0: 0.015
1: 0.110
2: 0.062
3: 0.106
4: 0.070
5: 0.058
6: 0.028
7: 0.149
8: 0.056
9: 0.347
1/1 [==============================] - 0s 90ms/step
./my_writing_dataset/test/31.JPG
0: 0.003
1: 0.012
2: 0.079
3: 0.333
4: 0.084
5: 0.159
6: 0.042
7: 0.086
8: 0.067
9: 0.134
1/1 [==============================] - 0s 83ms/step
./my_writing_dataset/test/41.JPG
0: 0.002
1: 0.010
2: 0.017
3: 0.007
4: 0.686
5: 0.043
6: 0.014
7: 0.015
8: 0.115
9: 0.090
1/1 [==============================] - 0s 89ms/step
./my_writing_dataset/test/51.JPG
0: 0.000
1: 0.000
2: 0.000
3: 0.013
4: 0.000
5: 0.969
6: 0.003
7: 0.001
8: 0.000
9: 0.012
1/1 [==============================] - 0s 85ms/step
./my_writing_dataset/test/61.JPG
0: 0.005
1: 0.001
2: 0.007
3: 0.013
4: 0.002
5: 0.398
6: 0.510
7: 0.001
8: 0.050
9: 0.013
1/1 [==============================] - 0s 87ms/step
./my_writing_dataset/test/71.JPG
0: 0.001
1: 0.141
2: 0.030
3: 0.002
4: 0.111
5: 0.004
6: 0.000
7: 0.697
8: 0.002
9: 0.013
1/1 [==============================] - 0s 96ms/step
./my_writing_dataset/test/81.JPG
0: 0.000
1: 0.000
2: 0.001
3: 0.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 0.996
9: 0.002
1/1 [==============================] - 0s 86ms/step
./my_writing_dataset/test/82.JPG
0: 0.021
1: 0.244
2: 0.017
3: 0.090
4: 0.040
5: 0.173
6: 0.048
7: 0.030
8: 0.285
9: 0.052
1/1 [==============================] - 0s 263ms/step
./my_writing_dataset/test/91.JPG
0: 0.001
1: 0.001
2: 0.020
3: 0.080
4: 0.001
5: 0.003
6: 0.008
7: 0.027
8: 0.015
9: 0.844
1/1 [==============================] - 0s 97ms/step
./my_writing_dataset/test/92.JPG
0: 0.000
1: 0.000
2: 0.000
3: 0.003
4: 0.006
5: 0.623
6: 0.000
7: 0.001
8: 0.000
9: 0.367
1/1 [==============================] - 0s 89ms/step
./my_writing_dataset/test/t0_1.jpg
0: 0.998
1: 0.000
2: 0.000
3: 0.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 0.000
9: 0.002
1/1 [==============================] - 0s 91ms/step
./my_writing_dataset/test/t1_1.jpg
0: 0.000
1: 1.000
2: 0.000
3: 0.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 0.000
9: 0.000
1/1 [==============================] - 0s 92ms/step
./my_writing_dataset/test/t2_1.jpg
0: 0.000
1: 0.000
2: 0.880
3: 0.000
4: 0.000
5: 0.000
6: 0.000
7: 0.090
8: 0.000
9: 0.029
1/1 [==============================] - 0s 89ms/step
./my_writing_dataset/test/t3_1.jpg
0: 0.000
1: 0.000
2: 0.000
3: 1.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 0.000
9: 0.000
1/1 [==============================] - 0s 92ms/step
./my_writing_dataset/test/t4_1.jpg
0: 0.000
1: 0.000
2: 0.000
3: 0.000
4: 1.000
5: 0.000
6: 0.000
7: 0.000
8: 0.000
9: 0.000
1/1 [==============================] - 0s 91ms/step
./my_writing_dataset/test/t5_1.jpg
0: 0.000
1: 0.000
2: 0.000
3: 0.000
4: 0.000
5: 1.000
6: 0.000
7: 0.000
8: 0.000
9: 0.000
1/1 [==============================] - 0s 91ms/step
./my_writing_dataset/test/t6_1.jpg
0: 0.000
1: 0.000
2: 0.000
3: 0.000
4: 0.000
5: 0.021
6: 0.971
7: 0.000
8: 0.007
9: 0.000
1/1 [==============================] - 0s 91ms/step
./my_writing_dataset/test/t7_1.jpg
0: 0.000
1: 0.001
2: 0.001
3: 0.001
4: 0.000
5: 0.002
6: 0.000
7: 0.993
8: 0.000
9: 0.001
1/1 [==============================] - 0s 95ms/step
./my_writing_dataset/test/t8_1.jpg
0: 0.000
1: 0.000
2: 0.000
3: 0.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 1.000
9: 0.000
1/1 [==============================] - 0s 92ms/step
./my_writing_dataset/test/t9_1.jpg
0: 0.000
1: 0.000
2: 0.000
3: 0.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 0.000
9: 1.000

(class) C:\Users\wlsgh\class\project2>C:/Users/wlsgh/anaconda3/envs/class/python.exe c:/Users/wlsgh/class/project2/MNIST_classifier.py
Traceback (most recent call last):
  File "c:/Users/wlsgh/class/project2/MNIST_classifier.py", line 220, in <module>
    Evaluation(test_image)
  File "c:/Users/wlsgh/class/project2/MNIST_classifier.py", line 131, in Evaluation
    model = tf.keras.models.load_model(f'{save_dir}/CNN_classifier_model.keras')
  File "C:\Users\wlsgh\anaconda3\envs\class\lib\site-packages\keras\src\saving\saving_api.py", line 238, in load_model
    return legacy_sm_saving_lib.load_model(
  File "C:\Users\wlsgh\anaconda3\envs\class\lib\site-packages\keras\src\utils\traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "C:\Users\wlsgh\anaconda3\envs\class\lib\site-packages\keras\src\saving\legacy\save.py", line 234, in load_model
    raise IOError(
OSError: No file or directory found at ./model/CNN_classifier_model.keras

(class) C:\Users\wlsgh\class\project2>C:/Users/wlsgh/anaconda3/envs/class/python.exe c:/Users/wlsgh/class/project2/MNIST_classifier.py
2024-06-16 07:03:43.859266: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 conv2d (Conv2D)             (None, 24, 24, 32)        832

 max_pooling2d (MaxPooling2  (None, 12, 12, 32)        0
 D)

 dropout (Dropout)           (None, 12, 12, 32)        0

 conv2d_1 (Conv2D)           (None, 12, 12, 64)        18496

 max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0
 g2D)

 dropout_1 (Dropout)         (None, 6, 6, 64)          0

 conv2d_2 (Conv2D)           (None, 6, 6, 128)         73856

 max_pooling2d_2 (MaxPoolin  (None, 3, 3, 128)         0
 g2D)

 dropout_2 (Dropout)         (None, 3, 3, 128)         0

 conv2d_3 (Conv2D)           (None, 3, 3, 256)         295168

 max_pooling2d_3 (MaxPoolin  (None, 2, 2, 256)         0
 g2D)

 dropout_3 (Dropout)         (None, 2, 2, 256)         0

 flatten (Flatten)           (None, 1024)              0

 dense (Dense)               (None, 512)               524800

 dropout_4 (Dropout)         (None, 512)               0

 dense_1 (Dense)             (None, 10)                5130

=================================================================
Total params: 918282 (3.50 MB)
Trainable params: 918282 (3.50 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Epoch 1/30
320/320 [==============================] - 46s 140ms/step - loss: 1.4007 - accuracy: 0.5040 - val_loss: 0.3156 - val_accuracy: 0.8989
Epoch 2/30
320/320 [==============================] - 47s 145ms/step - loss: 0.5334 - accuracy: 0.8221 - val_loss: 0.1737 - val_accuracy: 0.9451
Epoch 3/30
320/320 [==============================] - 47s 145ms/step - loss: 0.4189 - accuracy: 0.8586 - val_loss: 0.1194 - val_accuracy: 0.9629
Epoch 4/30
320/320 [==============================] - 47s 145ms/step - loss: 0.3775 - accuracy: 0.8707 - val_loss: 0.1075 - val_accuracy: 0.9669
Epoch 5/30
320/320 [==============================] - 48s 150ms/step - loss: 0.3454 - accuracy: 0.8822 - val_loss: 0.1228 - val_accuracy: 0.9634
Epoch 6/30
320/320 [==============================] - 48s 150ms/step - loss: 0.3263 - accuracy: 0.8869 - val_loss: 0.0964 - val_accuracy: 0.9702
Epoch 7/30
320/320 [==============================] - 48s 150ms/step - loss: 0.3144 - accuracy: 0.8919 - val_loss: 0.0853 - val_accuracy: 0.9728
Epoch 8/30
320/320 [==============================] - 48s 149ms/step - loss: 0.3017 - accuracy: 0.8963 - val_loss: 0.0780 - val_accuracy: 0.9756
Epoch 9/30
320/320 [==============================] - 48s 150ms/step - loss: 0.2933 - accuracy: 0.8986 - val_loss: 0.0704 - val_accuracy: 0.9772
Epoch 10/30
320/320 [==============================] - 48s 150ms/step - loss: 0.2831 - accuracy: 0.9008 - val_loss: 0.0839 - val_accuracy: 0.9745
Epoch 11/30
320/320 [==============================] - 45s 141ms/step - loss: 0.2791 - accuracy: 0.9027 - val_loss: 0.0588 - val_accuracy: 0.9820
Epoch 12/30
320/320 [==============================] - 46s 143ms/step - loss: 0.2714 - accuracy: 0.9051 - val_loss: 0.0630 - val_accuracy: 0.9810
Epoch 13/30
320/320 [==============================] - 47s 148ms/step - loss: 0.2654 - accuracy: 0.9062 - val_loss: 0.0747 - val_accuracy: 0.9768
Epoch 14/30
320/320 [==============================] - 47s 146ms/step - loss: 0.2618 - accuracy: 0.9079 - val_loss: 0.0618 - val_accuracy: 0.9816
Epoch 15/30
320/320 [==============================] - 47s 148ms/step - loss: 0.2606 - accuracy: 0.9079 - val_loss: 0.0566 - val_accuracy: 0.9822
Epoch 16/30
320/320 [==============================] - 47s 147ms/step - loss: 0.2586 - accuracy: 0.9096 - val_loss: 0.0622 - val_accuracy: 0.9827
Epoch 17/30
320/320 [==============================] - 47s 146ms/step - loss: 0.2515 - accuracy: 0.9112 - val_loss: 0.0599 - val_accuracy: 0.9836
Epoch 18/30
320/320 [==============================] - 45s 139ms/step - loss: 0.2470 - accuracy: 0.9133 - val_loss: 0.0554 - val_accuracy: 0.9840
Epoch 19/30
320/320 [==============================] - 46s 144ms/step - loss: 0.2490 - accuracy: 0.9124 - val_loss: 0.0711 - val_accuracy: 0.9786
Epoch 20/30
320/320 [==============================] - 45s 139ms/step - loss: 0.2443 - accuracy: 0.9133 - val_loss: 0.0577 - val_accuracy: 0.9828
Epoch 21/30
320/320 [==============================] - 46s 145ms/step - loss: 0.2433 - accuracy: 0.9145 - val_loss: 0.0457 - val_accuracy: 0.9855
Epoch 22/30
320/320 [==============================] - 45s 140ms/step - loss: 0.2408 - accuracy: 0.9144 - val_loss: 0.0520 - val_accuracy: 0.9856
Epoch 23/30
320/320 [==============================] - 45s 141ms/step - loss: 0.2386 - accuracy: 0.9171 - val_loss: 0.0471 - val_accuracy: 0.9877
Epoch 24/30
320/320 [==============================] - 46s 145ms/step - loss: 0.2357 - accuracy: 0.9167 - val_loss: 0.0580 - val_accuracy: 0.9828
Epoch 25/30
320/320 [==============================] - 46s 142ms/step - loss: 0.2313 - accuracy: 0.9183 - val_loss: 0.0673 - val_accuracy: 0.9804
Epoch 26/30
320/320 [==============================] - 46s 144ms/step - loss: 0.2310 - accuracy: 0.9182 - val_loss: 0.0454 - val_accuracy: 0.9861
Epoch 27/30
320/320 [==============================] - 44s 136ms/step - loss: 0.2323 - accuracy: 0.9177 - val_loss: 0.0552 - val_accuracy: 0.9845
Epoch 28/30
320/320 [==============================] - 44s 136ms/step - loss: 0.2275 - accuracy: 0.9182 - val_loss: 0.0535 - val_accuracy: 0.9845
Epoch 29/30
320/320 [==============================] - 45s 141ms/step - loss: 0.2269 - accuracy: 0.9186 - val_loss: 0.0432 - val_accuracy: 0.9869
Epoch 30/30
320/320 [==============================] - 46s 145ms/step - loss: 0.2269 - accuracy: 0.9194 - val_loss: 0.0540 - val_accuracy: 0.9846
1997/1997 [==============================] - 16s 8ms/step - loss: 0.1896 - accuracy: 0.9323
Train Accuracy = 0.932332
313/313 [==============================] - 3s 8ms/step - loss: 0.0540 - accuracy: 0.9846
Validation Accuracy = 0.984600

(class) C:\Users\wlsgh\class\project2>C:/Users/wlsgh/anaconda3/envs/class/python.exe c:/Users/wlsgh/class/project2/MNIST_classifier.py
2024-06-16 07:27:34.414761: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.1/1 [==============================] - 0s 165ms/step
./my_writing_dataset/test/01.JPG
0: 0.990
1: 0.000
2: 0.001
3: 0.000
4: 0.000
5: 0.000
6: 0.003
7: 0.000
8: 0.001
9: 0.005
1/1 [==============================] - 0s 79ms/step
./my_writing_dataset/test/02.JPG
0: 0.646
1: 0.000
2: 0.003
3: 0.000
4: 0.000
5: 0.000
6: 0.026
7: 0.001
8: 0.001
9: 0.322
1/1 [==============================] - 0s 80ms/step
./my_writing_dataset/test/03.JPG
0: 0.006
1: 0.000
2: 0.002
3: 0.001
4: 0.000
5: 0.000
6: 0.005
7: 0.004
8: 0.002
9: 0.980
1/1 [==============================] - 0s 87ms/step
./my_writing_dataset/test/11.JPG
0: 0.002
1: 0.893
2: 0.017
3: 0.002
4: 0.032
5: 0.005
6: 0.007
7: 0.021
8: 0.006
9: 0.015
WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029E6EE0A160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has 
reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing 
and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
1/1 [==============================] - 0s 88ms/step
./my_writing_dataset/test/2.jpg
0: 0.000
1: 0.000
2: 0.000
3: 1.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 0.000
9: 0.000
WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029E6EE40310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has 
reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing 
and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
1/1 [==============================] - 0s 85ms/step
./my_writing_dataset/test/21.JPG
0: 0.042
1: 0.095
2: 0.083
3: 0.101
4: 0.131
5: 0.070
6: 0.094
7: 0.081
8: 0.131
9: 0.172
1/1 [==============================] - 0s 78ms/step
./my_writing_dataset/test/31.JPG
0: 0.026
1: 0.038
2: 0.077
3: 0.091
4: 0.114
5: 0.023
6: 0.029
7: 0.162
8: 0.019
9: 0.421
1/1 [==============================] - 0s 85ms/step
./my_writing_dataset/test/41.JPG
0: 0.011
1: 0.212
2: 0.035
3: 0.011
4: 0.387
5: 0.028
6: 0.027
7: 0.024
8: 0.071
9: 0.195
1/1 [==============================] - 0s 91ms/step
./my_writing_dataset/test/51.JPG
0: 0.001
1: 0.000
2: 0.000
3: 0.008
4: 0.002
5: 0.913
6: 0.022
7: 0.009
8: 0.002
9: 0.043
1/1 [==============================] - 0s 76ms/step
./my_writing_dataset/test/61.JPG
0: 0.015
1: 0.005
2: 0.012
3: 0.012
4: 0.019
5: 0.451
6: 0.347
7: 0.019
8: 0.063
9: 0.058
1/1 [==============================] - 0s 80ms/step
./my_writing_dataset/test/71.JPG
0: 0.002
1: 0.309
2: 0.229
3: 0.006
4: 0.034
5: 0.011
6: 0.011
7: 0.391
8: 0.005
9: 0.003
1/1 [==============================] - 0s 87ms/step
./my_writing_dataset/test/81.JPG
0: 0.002
1: 0.004
2: 0.025
3: 0.003
4: 0.008
5: 0.001
6: 0.001
7: 0.041
8: 0.623
9: 0.291
1/1 [==============================] - 0s 87ms/step
./my_writing_dataset/test/82.JPG
0: 0.001
1: 0.648
2: 0.025
3: 0.011
4: 0.083
5: 0.127
6: 0.032
7: 0.016
8: 0.045
9: 0.013
1/1 [==============================] - 0s 252ms/step
./my_writing_dataset/test/91.JPG
0: 0.072
1: 0.003
2: 0.075
3: 0.025
4: 0.002
5: 0.021
6: 0.081
7: 0.098
8: 0.031
9: 0.592
1/1 [==============================] - 0s 88ms/step
./my_writing_dataset/test/92.JPG
0: 0.000
1: 0.000
2: 0.000
3: 0.004
4: 0.079
5: 0.323
6: 0.000
7: 0.004
8: 0.001
9: 0.588
1/1 [==============================] - 0s 86ms/step
./my_writing_dataset/test/t0_1.jpg
0: 0.998
1: 0.000
2: 0.000
3: 0.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 0.000
9: 0.002
1/1 [==============================] - 0s 87ms/step
./my_writing_dataset/test/t1_1.jpg
0: 0.000
1: 1.000
2: 0.000
3: 0.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 0.000
9: 0.000
1/1 [==============================] - 0s 89ms/step
./my_writing_dataset/test/t2_1.jpg
0: 0.000
1: 0.000
2: 0.991
3: 0.000
4: 0.000
5: 0.000
6: 0.000
7: 0.004
8: 0.000
9: 0.004
1/1 [==============================] - 0s 85ms/step
./my_writing_dataset/test/t3_1.jpg
0: 0.000
1: 0.000
2: 0.000
3: 1.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 0.000
9: 0.000
1/1 [==============================] - 0s 87ms/step
./my_writing_dataset/test/t4_1.jpg
0: 0.000
1: 0.000
2: 0.000
3: 0.000
4: 0.999
5: 0.000
6: 0.000
7: 0.001
8: 0.000
9: 0.000
1/1 [==============================] - 0s 77ms/step
./my_writing_dataset/test/t5_1.jpg
0: 0.000
1: 0.000
2: 0.000
3: 0.000
4: 0.000
5: 1.000
6: 0.000
7: 0.000
8: 0.000
9: 0.000
1/1 [==============================] - 0s 80ms/step
./my_writing_dataset/test/t6_1.jpg
0: 0.000
1: 0.000
2: 0.000
3: 0.001
4: 0.002
5: 0.295
6: 0.679
7: 0.000
8: 0.012
9: 0.009
1/1 [==============================] - 0s 86ms/step
./my_writing_dataset/test/t7_1.jpg
0: 0.000
1: 0.000
2: 0.000
3: 0.000
4: 0.000
5: 0.000
6: 0.000
7: 0.999
8: 0.000
9: 0.000
1/1 [==============================] - 0s 103ms/step
./my_writing_dataset/test/t8_1.jpg
0: 0.000
1: 0.000
2: 0.000
3: 0.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 1.000
9: 0.000
1/1 [==============================] - 0s 81ms/step
./my_writing_dataset/test/t9_1.jpg
0: 0.000
1: 0.000
2: 0.000
3: 0.000
4: 0.000
5: 0.000
6: 0.000
7: 0.000
8: 0.000
9: 1.000